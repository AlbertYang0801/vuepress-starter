# 数据日志分段存储

## 数据保存机制

![image.png](https://s2.loli.net/2025/06/26/4Q9SwYra8dDFPpy.png)

Kafka 的数据是按照分区存储的，以 topic-partition 为目录保存数据。

数据是存到 log 中，而 log 又引入了LogSegment机制。

`log.segment.bytes`，默认 1G。当超过1G 之后，日志就会开始分割。

而日志分段文件以及索引文件都是以基准偏移量（offset）命名的。

基本每段的日志文件包含一个数据文件和两个索引文件。

- 以offset 为索引的 `.index`。
- 以时间戳为索引的 `.timeindex`。

索引里面并不是保留全量的数据索引，而是以**稀疏索引**的方式保存（方便使用二分查找快速定位数据）。

![image.png](https://s2.loli.net/2025/06/26/nKFA5i8dylUTDOS.png)

![image.png](https://s2.loli.net/2025/06/26/xLB2qVahErIZfvi.png)

所以也可以看到 Kafka 中分区的数据，是按照顺序写的方式在磁盘上保存，写入比随机写性能要快。

## 数据删除机制

Kafka 的数据删除主要受到参数影响。

- `log.retention.bytes`按文件总大小保留
- `log.retention.hours`、`log.retention.ms` 等按时间保留

> Kafka 内部有个 Log Clean 会定时清理过期的日志。